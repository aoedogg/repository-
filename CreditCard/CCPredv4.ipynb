{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import matplotlib\n", "import matplotlib.pyplot as plt\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "import tensorflow as tf\n", "from tensorflow import keras  # tf.keras\n", "import seaborn as sns\n", "from sklearn.metrics import confusion_matrix\n", "from sklearn.metrics import recall_score\n", "from sklearn.preprocessing import OneHotEncoder\n", "from sklearn.decomposition import PCA\n", "from imblearn.over_sampling import BorderlineSMOTE\n", "import sys\n", "from sklearn.ensemble import RandomForestClassifier"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Our top priority in this business problem is to identify customers who are getting churned.<br>\n", "Even if we predict non-churning customers as churned, it won't harm our business. But predicting churning customers as Non-churning will do. So recall (TP/TP+FN) need to be higher."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = pd.read_csv('BankChurners.csv')\n", "data.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], inplace = True)\n", "data.drop(columns=['CLIENTNUM'], inplace = True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(data.shape)\n", "# One hot encoding for multi-category features\n", "Education_Level_ohe = pd.get_dummies(data['Education_Level'], prefix='Education')\n", "data.join(Education_Level_ohe)\n", "Income_Category_ohe = pd.get_dummies(data['Income_Category'], prefix='Income')\n", "data.join(Income_Category_ohe)\n", "Card_Category_ohe = pd.get_dummies(data['Card_Category'], prefix='Card_Category')\n", "data.join(Card_Category_ohe)\n", "Marital_Status_ohe = pd.get_dummies(data['Marital_Status'], prefix='Marital_Status')\n", "data.join(Marital_Status_ohe)\n", "data.drop(columns=['Education_Level','Income_Category','Card_Category', 'Marital_Status'], inplace = True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Here  binary categorical variables are converted into ints."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cat_ints = ['Attrition_Flag', 'Gender']\n", "for columns in cat_ints:\n", "    data[columns] = pd.Categorical(data[columns])\n", "    data[columns] = data[columns].cat.codes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(data.columns)\n", "print(data.head(100))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split into X, y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = data.drop(columns=['Attrition_Flag'])\n", "y = data['Attrition_Flag']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plit data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n", "print(X_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Modify data with oversampling"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["smote = BorderlineSMOTE()\n", "x_smote, y_smote = smote.fit_resample(X_train,y_train)\n", "X_train = x_smote\n", "y_train = y_smote"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Normalize"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = StandardScaler()\n", "X_train_scaled = scaler.fit_transform(X_train)\n", "X_test_scaled = scaler.transform(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Testing / Validation split"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_validate_scaled, X_test_scaled, y_validate, y_test = train_test_split(X_test_scaled, y_test, test_size=0.5, random_state=42)\n", "print(\"Shape of training data: \", X_train_scaled.shape)\n", "print(\"Shape of testing data: \" ,X_test_scaled.shape)\n", "print(\"Shape of validation data: \" ,X_validate_scaled.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["number of input features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_feat = X_train_scaled.shape[1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train random forest classifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clf = RandomForestClassifier()\n", "clf.fit(X_train_scaled, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Evaluation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = (clf.predict(X_test_scaled))\n", "print(confusion_matrix(y_test, y_pred))\n", "print(recall_score(1 - y_test, 1 -  y_pred))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}